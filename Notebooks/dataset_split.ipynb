{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b85cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c072d",
   "metadata": {},
   "source": [
    "*Upload Structure*\n",
    "```\n",
    "Data/\n",
    "└── data_folder/\n",
    "    ├── images/                 # Images unsplit\n",
    "    |\n",
    "    └── annotations/            # JSON in COCO format\n",
    "        └── instances.json\n",
    "```\n",
    "\n",
    "*Repo Structure*\n",
    "```\n",
    "Data/\n",
    "└── data_folder/\n",
    "    ├── images/                 # Images split in train and val set\n",
    "    |   ├── train/\n",
    "    |   └── val/\n",
    "    └── annotations/            # JSON train and val files in COCO format\n",
    "        ├── instances_train.json\n",
    "        └── instances_val.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30e2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset_folder, val_size, random_seed=42):\n",
    "    \"\"\"\n",
    "    Split a single COCO dataset (no prior split) into TRAIN and VAL sets.\n",
    "\n",
    "    Input (unsplit):\n",
    "        dataset/\n",
    "          images/\n",
    "            img_0001.png ...\n",
    "          annotations/\n",
    "            instances.json\n",
    "\n",
    "    Output (created):\n",
    "        dataset/\n",
    "          images/\n",
    "            train/\n",
    "            val/\n",
    "          annotations/\n",
    "            instances_train.json\n",
    "            instances_val.json\n",
    "    \"\"\"\n",
    "    dataset_folder = Path(dataset_folder)\n",
    "    img_dir = dataset_folder / \"images\"\n",
    "    ann_dir = dataset_folder / \"annotations\"\n",
    "\n",
    "    # 1) Locate the single COCO annotation file\n",
    "    ann_candidates = [p for p in ann_dir.glob(\"*.json\")]\n",
    "    if not ann_candidates:\n",
    "        raise FileNotFoundError(f\"No JSON annotations found in {ann_dir}\")\n",
    "\n",
    "    coco_path = None\n",
    "    coco = None\n",
    "    for p in ann_candidates:\n",
    "        try:\n",
    "            obj = json.loads((p.read_text(encoding=\"utf-8\")))\n",
    "            if isinstance(obj, dict) and {\"images\",\"annotations\",\"categories\"} <= obj.keys():\n",
    "                coco_path = p\n",
    "                coco = obj\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    if coco_path is None:\n",
    "        raise ValueError(\"No valid COCO annotations file found (missing images/annotations/categories).\")\n",
    "\n",
    "    # Helper: resolve a file_name as stored in COCO to an absolute source path,\n",
    "    # relative to the annotations file location if needed.\n",
    "    def resolve_src_path(file_name: str) -> Path:\n",
    "        p = Path(file_name)\n",
    "        if p.is_absolute():\n",
    "            return p\n",
    "        # COCO file_name is relative to the JSON location in many datasets\n",
    "        return (coco_path.parent / p).resolve()\n",
    "\n",
    "    # 2) Collect image entries that actually exist on disk\n",
    "    image_entries = coco.get(\"images\", [])\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "    def exists_im(entry):\n",
    "        src = resolve_src_path(entry[\"file_name\"])\n",
    "        return src.suffix.lower() in exts and src.is_file()\n",
    "\n",
    "    image_entries = [im for im in image_entries if exists_im(im)]\n",
    "    if not image_entries:\n",
    "        raise ValueError(\"No matching images found on disk for the entries in the COCO file.\")\n",
    "\n",
    "    # 3) Build splits\n",
    "    rng = random.Random(random_seed)\n",
    "    indices = list(range(len(image_entries)))\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    N = len(indices)\n",
    "    if 0 < val_size < 1:\n",
    "        n_val = max(1, int(round(val_size * N)))\n",
    "    else:\n",
    "        n_val = int(val_size)\n",
    "    n_val = min(max(1, n_val), N - 1)  # keep at least 1 for train\n",
    "\n",
    "    val_idx = set(indices[:n_val])\n",
    "    train_idx = set(indices[n_val:])\n",
    "\n",
    "    val_images = [image_entries[i] for i in range(N) if i in val_idx]\n",
    "    train_images = [image_entries[i] for i in range(N) if i in train_idx]\n",
    "\n",
    "    val_image_ids = {im[\"id\"] for im in val_images}\n",
    "    train_image_ids = {im[\"id\"] for im in train_images}\n",
    "\n",
    "    # 4) Filter annotations per split\n",
    "    anns = coco.get(\"annotations\", [])\n",
    "    val_anns = [a for a in anns if a.get(\"image_id\") in val_image_ids]\n",
    "    train_anns = [a for a in anns if a.get(\"image_id\") in train_image_ids]\n",
    "\n",
    "    # 5) Prepare output dirs\n",
    "    (img_dir / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (img_dir / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 6) Copy images using resolved source paths; write into images/{split}/<basename>\n",
    "    def copy_images(entries, split_name):\n",
    "        dst_dir = img_dir / split_name\n",
    "        for im in entries:\n",
    "            src = resolve_src_path(im[\"file_name\"])\n",
    "            name = src.name  # use basename to avoid duplicating subpaths like ../images/...\n",
    "            dst = dst_dir / name\n",
    "            if not dst.exists():\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "    copy_images(val_images, \"val\")\n",
    "    copy_images(train_images, \"train\")\n",
    "\n",
    "    # 7) Build COCO dicts with updated file_name pointing from annotations/ to images/{split}/...\n",
    "    def remap_images(entries, split_name):\n",
    "        out = []\n",
    "        for im in entries:\n",
    "            src = resolve_src_path(im[\"file_name\"])\n",
    "            im2 = dict(im)\n",
    "            im2[\"file_name\"] = f\"../images/{split_name}/{src.name}\"\n",
    "            out.append(im2)\n",
    "        return out\n",
    "\n",
    "    base = {\n",
    "        \"info\": coco.get(\"info\", {}),\n",
    "        \"licenses\": coco.get(\"licenses\", []),\n",
    "        \"categories\": coco.get(\"categories\", []),\n",
    "    }\n",
    "\n",
    "    val_coco = dict(base)\n",
    "    val_coco[\"images\"] = remap_images(val_images, \"val\")\n",
    "    val_coco[\"annotations\"] = val_anns\n",
    "\n",
    "    train_coco = dict(base)\n",
    "    train_coco[\"images\"] = remap_images(train_images, \"train\")\n",
    "    train_coco[\"annotations\"] = train_anns\n",
    "\n",
    "    # 8) Write split COCO JSONs\n",
    "    with (ann_dir / \"instances_val.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(val_coco, f, ensure_ascii=False, indent=2)\n",
    "    with (ann_dir / \"instances_train.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train_coco, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 9) Simple report\n",
    "    summary = {\n",
    "        \"total_images\": N,\n",
    "        \"val_images\": len(val_coco[\"images\"]),\n",
    "        \"train_images\": len(train_coco[\"images\"]),\n",
    "        \"val_annotations\": len(val_anns),\n",
    "        \"train_annotations\": len(train_anns),\n",
    "        \"random_seed\": random_seed,\n",
    "        \"source_annotations\": str(coco_path.name),\n",
    "    }\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65370bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_val_split\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../Data/tomatoes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mtrain_val_split\u001b[39m\u001b[34m(dataset_folder, val_size, random_seed)\u001b[39m\n\u001b[32m    127\u001b[39m val_coco[\u001b[33m\"\u001b[39m\u001b[33mannotations\u001b[39m\u001b[33m\"\u001b[39m] = val_anns\n\u001b[32m    129\u001b[39m train_coco = \u001b[38;5;28mdict\u001b[39m(base)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m train_coco[\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mremap_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m train_coco[\u001b[33m\"\u001b[39m\u001b[33mannotations\u001b[39m\u001b[33m\"\u001b[39m] = train_anns\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# 8) Write split COCO JSONs\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mtrain_val_split.<locals>.remap_images\u001b[39m\u001b[34m(entries, split_name)\u001b[39m\n\u001b[32m    111\u001b[39m out = []\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m entries:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     src = \u001b[43mresolve_src_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     im2 = \u001b[38;5;28mdict\u001b[39m(im)\n\u001b[32m    115\u001b[39m     im2[\u001b[33m\"\u001b[39m\u001b[33mfile_name\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m../images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mtrain_val_split.<locals>.resolve_src_path\u001b[39m\u001b[34m(file_name)\u001b[39m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# COCO file_name is relative to the JSON location in many datasets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mcoco_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/thesis-env/lib/python3.11/pathlib.py:1003\u001b[39m, in \u001b[36mPath.resolve\u001b[39m\u001b[34m(self, strict)\u001b[39m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m         \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1005\u001b[39m         check_eloop(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/thesis-env/lib/python3.11/pathlib.py:1013\u001b[39m, in \u001b[36mPath.stat\u001b[39m\u001b[34m(self, follow_symlinks)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, follow_symlinks=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1009\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[33;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[33;03m    os.stat() does.\u001b[39;00m\n\u001b[32m   1012\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m os.stat(\u001b[38;5;28mself\u001b[39m, follow_symlinks=follow_symlinks)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_val_split(\"../Data/tomatoes\", val_size=0.20, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efff6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_coco_images(\n",
    "    dataset_root, \n",
    "    split=\"train\", \n",
    "    num_samples=3, \n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Display random COCO images with bounding boxes and category labels.\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str | Path): Path to dataset root (containing 'images/' and 'annotations/').\n",
    "        split (str): 'train' or 'val', determines which annotation file to load.\n",
    "        num_samples (int): Number of random images to display.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    dataset_root = Path(dataset_root)\n",
    "    ann_path = dataset_root / \"annotations\" / f\"instances_{split}.json\"\n",
    "    ann_dir = ann_path.parent\n",
    "\n",
    "    if not ann_path.exists():\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {ann_path}\")\n",
    "\n",
    "    with open(ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    cats = {c[\"id\"]: c[\"name\"] for c in coco[\"categories\"]}\n",
    "    images = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "    anns = coco[\"annotations\"]\n",
    "\n",
    "    # group annotations by image_id\n",
    "    ann_by_img = {}\n",
    "    for a in anns:\n",
    "        ann_by_img.setdefault(a[\"image_id\"], []).append(a)\n",
    "\n",
    "    # random image selection\n",
    "    rng = random.Random(seed)\n",
    "    sample_ids = rng.sample(list(images.keys()), min(num_samples, len(images)))\n",
    "\n",
    "    for img_id in sample_ids:\n",
    "        img_info = images[img_id]\n",
    "        img_path = (ann_dir / img_info[\"file_name\"]).resolve()\n",
    "\n",
    "        if not img_path.exists():\n",
    "            print(f\"Missing: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        im = Image.open(img_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(im)\n",
    "\n",
    "        for a in ann_by_img.get(img_id, []):\n",
    "            if \"bbox\" not in a:\n",
    "                continue\n",
    "            x, y, w, h = a[\"bbox\"]\n",
    "            cat = cats.get(a[\"category_id\"], \"\")\n",
    "            draw.rectangle([x, y, x + w, y + h], outline=\"red\", width=2)\n",
    "            draw.text((x, y), cat, fill=\"red\")\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(im)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(img_info[\"file_name\"])\n",
    "        plt.show(block=False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53502308",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_coco_images(\"../Data/tomatoes\", split=\"train\", num_samples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8686e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_coco_images(\"../Data/tomatoes\", split=\"val\", num_samples=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
