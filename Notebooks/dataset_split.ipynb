{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b85cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c072d",
   "metadata": {},
   "source": [
    "*Upload Structure*\n",
    "```\n",
    "Data/\n",
    "└── data_folder/\n",
    "    ├── images/                 # Images unsplit\n",
    "    |\n",
    "    └── annotations/            # JSON in COCO format\n",
    "        └── instances.json\n",
    "```\n",
    "\n",
    "*Repo Structure*\n",
    "```\n",
    "Data/\n",
    "└── data_folder/\n",
    "    ├── images/                 # Images split in train and val set\n",
    "    |   ├── train/\n",
    "    |   └── val/\n",
    "    └── annotations/            # JSON train and val files in COCO format\n",
    "        ├── instances_train.json\n",
    "        └── instances_val.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30e2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset_folder, val_size, random_seed=42):\n",
    "    \"\"\"\n",
    "    Split a single COCO dataset (no prior split) into TRAIN and VAL sets.\n",
    "\n",
    "    Input (unsplit):\n",
    "        dataset/\n",
    "          images/\n",
    "            img_0001.png ...\n",
    "          annotations/\n",
    "            instances.json\n",
    "\n",
    "    Output (created):\n",
    "        dataset/\n",
    "          images/\n",
    "            train/\n",
    "            val/\n",
    "          annotations/\n",
    "            instances_train.json\n",
    "            instances_val.json\n",
    "    \"\"\"\n",
    "    dataset_folder = Path(dataset_folder)\n",
    "    img_dir = dataset_folder / \"images\"\n",
    "    ann_dir = dataset_folder / \"annotations\"\n",
    "\n",
    "    # 1) Locate the single COCO annotation file\n",
    "    ann_candidates = [p for p in ann_dir.glob(\"*.json\")]\n",
    "    if not ann_candidates:\n",
    "        raise FileNotFoundError(f\"No JSON annotations found in {ann_dir}\")\n",
    "\n",
    "    coco_path = None\n",
    "    coco = None\n",
    "    for p in ann_candidates:\n",
    "        try:\n",
    "            obj = json.loads((p.read_text(encoding=\"utf-8\")))\n",
    "            if isinstance(obj, dict) and {\"images\",\"annotations\",\"categories\"} <= obj.keys():\n",
    "                coco_path = p\n",
    "                coco = obj\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    if coco_path is None:\n",
    "        raise ValueError(\"No valid COCO annotations file found (missing images/annotations/categories).\")\n",
    "\n",
    "    # Helper: resolve a file_name as stored in COCO to an absolute source path,\n",
    "    # relative to the annotations file location if needed.\n",
    "    def resolve_src_path(file_name: str) -> Path:\n",
    "        p = Path(file_name)\n",
    "        if p.is_absolute():\n",
    "            return p\n",
    "        # COCO file_name is relative to the JSON location in many datasets\n",
    "        return (coco_path.parent / p).resolve()\n",
    "\n",
    "    # 2) Collect image entries that actually exist on disk\n",
    "    image_entries = coco.get(\"images\", [])\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "    def exists_im(entry):\n",
    "        src = resolve_src_path(entry[\"file_name\"])\n",
    "        return src.suffix.lower() in exts and src.is_file()\n",
    "\n",
    "    image_entries = [im for im in image_entries if exists_im(im)]\n",
    "    if not image_entries:\n",
    "        raise ValueError(\"No matching images found on disk for the entries in the COCO file.\")\n",
    "\n",
    "    # 3) Build splits\n",
    "    rng = random.Random(random_seed)\n",
    "    indices = list(range(len(image_entries)))\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    N = len(indices)\n",
    "    if 0 < val_size < 1:\n",
    "        n_val = max(1, int(round(val_size * N)))\n",
    "    else:\n",
    "        n_val = int(val_size)\n",
    "    n_val = min(max(1, n_val), N - 1)  # keep at least 1 for train\n",
    "\n",
    "    val_idx = set(indices[:n_val])\n",
    "    train_idx = set(indices[n_val:])\n",
    "\n",
    "    val_images = [image_entries[i] for i in range(N) if i in val_idx]\n",
    "    train_images = [image_entries[i] for i in range(N) if i in train_idx]\n",
    "\n",
    "    val_image_ids = {im[\"id\"] for im in val_images}\n",
    "    train_image_ids = {im[\"id\"] for im in train_images}\n",
    "\n",
    "    # 4) Filter annotations per split\n",
    "    anns = coco.get(\"annotations\", [])\n",
    "    val_anns = [a for a in anns if a.get(\"image_id\") in val_image_ids]\n",
    "    train_anns = [a for a in anns if a.get(\"image_id\") in train_image_ids]\n",
    "\n",
    "    # 5) Prepare output dirs\n",
    "    (img_dir / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (img_dir / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 6) Copy images using resolved source paths; write into images/{split}/<basename>\n",
    "    def copy_images(entries, split_name):\n",
    "        dst_dir = img_dir / split_name\n",
    "        for im in entries:\n",
    "            src = resolve_src_path(im[\"file_name\"])\n",
    "            name = src.name  # use basename to avoid duplicating subpaths like ../images/...\n",
    "            dst = dst_dir / name\n",
    "            if not dst.exists():\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "    copy_images(val_images, \"val\")\n",
    "    copy_images(train_images, \"train\")\n",
    "\n",
    "    # 7) Build COCO dicts with updated file_name pointing from annotations/ to images/{split}/...\n",
    "    def remap_images(entries, split_name):\n",
    "        out = []\n",
    "        for im in entries:\n",
    "            src = resolve_src_path(im[\"file_name\"])\n",
    "            im2 = dict(im)\n",
    "            im2[\"file_name\"] = f\"../images/{split_name}/{src.name}\"\n",
    "            out.append(im2)\n",
    "        return out\n",
    "\n",
    "    base = {\n",
    "        \"info\": coco.get(\"info\", {}),\n",
    "        \"licenses\": coco.get(\"licenses\", []),\n",
    "        \"categories\": coco.get(\"categories\", []),\n",
    "    }\n",
    "\n",
    "    val_coco = dict(base)\n",
    "    val_coco[\"images\"] = remap_images(val_images, \"val\")\n",
    "    val_coco[\"annotations\"] = val_anns\n",
    "\n",
    "    train_coco = dict(base)\n",
    "    train_coco[\"images\"] = remap_images(train_images, \"train\")\n",
    "    train_coco[\"annotations\"] = train_anns\n",
    "\n",
    "    # 8) Write split COCO JSONs\n",
    "    with (ann_dir / \"instances_val.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(val_coco, f, ensure_ascii=False, indent=2)\n",
    "    with (ann_dir / \"instances_train.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train_coco, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 9) Simple report\n",
    "    summary = {\n",
    "        \"total_images\": N,\n",
    "        \"val_images\": len(val_coco[\"images\"]),\n",
    "        \"train_images\": len(train_coco[\"images\"]),\n",
    "        \"val_annotations\": len(val_anns),\n",
    "        \"train_annotations\": len(train_anns),\n",
    "        \"random_seed\": random_seed,\n",
    "        \"source_annotations\": str(coco_path.name),\n",
    "    }\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65370bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_images': 6623,\n",
       " 'val_images': 1325,\n",
       " 'train_images': 5298,\n",
       " 'val_annotations': 9067,\n",
       " 'train_annotations': 35877,\n",
       " 'random_seed': 42,\n",
       " 'source_annotations': 'instances.json'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split(\"../Data/tomatoes\", val_size=0.20, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7efff6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_coco_images(\n",
    "    dataset_root, \n",
    "    split=\"train\", \n",
    "    num_samples=3, \n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Display random COCO images with bounding boxes and category labels.\n",
    "\n",
    "    Args:\n",
    "        dataset_root (str | Path): Path to dataset root (containing 'images/' and 'annotations/').\n",
    "        split (str): 'train' or 'val', determines which annotation file to load.\n",
    "        num_samples (int): Number of random images to display.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    dataset_root = Path(dataset_root)\n",
    "    ann_path = dataset_root / \"annotations\" / f\"instances_{split}.json\"\n",
    "    ann_dir = ann_path.parent\n",
    "\n",
    "    if not ann_path.exists():\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {ann_path}\")\n",
    "\n",
    "    with open(ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    cats = {c[\"id\"]: c[\"name\"] for c in coco[\"categories\"]}\n",
    "    images = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "    anns = coco[\"annotations\"]\n",
    "\n",
    "    # group annotations by image_id\n",
    "    ann_by_img = {}\n",
    "    for a in anns:\n",
    "        ann_by_img.setdefault(a[\"image_id\"], []).append(a)\n",
    "\n",
    "    # random image selection\n",
    "    rng = random.Random(seed)\n",
    "    sample_ids = rng.sample(list(images.keys()), min(num_samples, len(images)))\n",
    "\n",
    "    for img_id in sample_ids:\n",
    "        img_info = images[img_id]\n",
    "        img_path = (ann_dir / img_info[\"file_name\"]).resolve()\n",
    "\n",
    "        if not img_path.exists():\n",
    "            print(f\"Missing: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        im = Image.open(img_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(im)\n",
    "\n",
    "        for a in ann_by_img.get(img_id, []):\n",
    "            if \"bbox\" not in a:\n",
    "                continue\n",
    "            x, y, w, h = a[\"bbox\"]\n",
    "            cat = cats.get(a[\"category_id\"], \"\")\n",
    "            draw.rectangle([x, y, x + w, y + h], outline=\"red\", width=2)\n",
    "            draw.text((x, y), cat, fill=\"red\")\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(im)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(img_info[\"file_name\"])\n",
    "        plt.show(block=False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53502308",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_coco_images(\"../Data/tomatoes\", split=\"train\", num_samples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8686e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_coco_images(\"../Data/tomatoes\", split=\"val\", num_samples=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
